{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89efa4ec",
   "metadata": {},
   "source": [
    "# Email Spam Detection - Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8db05c",
   "metadata": {},
   "source": [
    "### Necessary Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22833d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ab2f34",
   "metadata": {},
   "source": [
    "### Loading and Exploring Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64a97a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_emails = pd.read_csv('emails.csv')\n",
    "dataframe_emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ebf7eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails: 5728\n",
      "Proportion of spam emails: 0.2388\n",
      "Proportion of ham emails: 0.7612\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of emails: {len(dataframe_emails)}\")\n",
    "print(f\"Proportion of spam emails: {dataframe_emails.spam.sum()/len(dataframe_emails):.4f}\")\n",
    "print(f\"Proportion of ham emails: {1-dataframe_emails.spam.sum()/len(dataframe_emails):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbc581",
   "metadata": {},
   "source": [
    "### Preprocessing Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aba0e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_emails(df):\n",
    "    \"\"\"\n",
    "    Preprocesses email data from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The input DataFrame containing email data with 'text' and 'spam' columns.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing two elements:\n",
    "        1. X (numpy.array): An array containing email content after removing the \"Subject:\" prefix.\n",
    "        2. Y (numpy.array): An array indicating whether each email is spam (1) or ham (0).\n",
    "\n",
    "    The function shuffles the input DataFrame to avoid biased results in train/test splits.\n",
    "    It then extracts email content and spam labels, removing the \"Subject:\" prefix from each email.\n",
    "\n",
    "    \"\"\"\n",
    "    # Shuffles the dataset\n",
    "    df = df.sample(frac = 1, ignore_index = True, random_state = 42)\n",
    "    # Removes the \"Subject:\" string, which comprises the first 9 characters of each email. Also, convert it to a numpy array.\n",
    "    X = df.text.apply(lambda x: x[9:]).to_numpy()\n",
    "    # Convert the labels to numpy array\n",
    "    Y = df.spam.to_numpy()\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af42252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n",
      "['re : energy derivatives conference - may 29 , toronto  good morning amy :  vince kaminski will need the following :  an lcd projector to hook up to a lap tap for his presentation  he will have dinner with the conference organizers and speakers on the 29 th .  he will need 2 nights ( the 28 th and the 29 th ) hotel reservations .  he will send you an abstract shortly .  thanks and have a great day !  shirley crenshaw  713 - 853 - 5290  amy aldous on 03 / 31 / 2000 10 : 50 : 11 am  to : shirley . crenshaw @ enron . com  cc :  subject : re : energy derivatives conference - may 29 , toronto  ms . crenshaw ,  thank you for sending the bio so quickly . it \\' s exactly what i was looking  for .  we are planning to compile the conference speakers \\' papers for distribution  to the participants . while i will not need dr . kaminski \\' s contribution for  several weeks , an abstract of his presentation as soon as possible would be  very useful to the conference organizers .  i will also need the following information :  - dr . kaminski \\' s audio / video equipment requirements for his presentation  - will he be joining the conference organizers and speakers for dinner on  may 29 ?  - which nights will he be staying in toronto ? i will reserve a room at the  conference hotel  - any dietary restrictions or special requests  your help is much appreciated .  best wishes ,  amy  at 11 : 50 am 3 / 30 / 00 - 0600 , you wrote :  >  > amy :  >  > attached please find a short \" bio \" for dr . kaminski . please let me know  > if i can help further .  >  >  > ( see attached file : vincent kaminski bio . doc )  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *  amy aldous , conference co - ordinator  centre for advanced studies in finance  university of waterloo  waterloo , on n 2 l 3 gl  tel : ( 519 ) 888 - 4567 ext . 5728  fax : ( 519 ) 888 - 7562  email : aaldous @ uwaterloo . ca  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *'\n",
      " 'financial maths course , part 2  vince ,  just in case , here is a draft copy of the event for you to refer to .  paul  - finmathmail . doc']\n"
     ]
    }
   ],
   "source": [
    "X, Y = preprocess_emails(dataframe_emails)\n",
    "print(Y[:2])\n",
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5978e2",
   "metadata": {},
   "source": [
    "### Preprocessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72b274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(X):\n",
    "    \"\"\"\n",
    "    Preprocesses a collection of text data by removing stopwords and punctuation.\n",
    "\n",
    "    Parameters:\n",
    "    - X (str or array-like): The input text data to be processed. If a single string is provided,\n",
    "      it will be converted into a one-element numpy array.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.array: An array of preprocessed text data, where each element represents a document\n",
    "      with stopwords and punctuation removed.\n",
    "\n",
    "    Note:\n",
    "    - The function uses the Natural Language Toolkit (nltk) library for tokenization and stopword removal.\n",
    "    - If the input is a single string, it is converted into a one-element numpy array.\n",
    "    \"\"\"\n",
    "    # Make a set with the stopwords and punctuation\n",
    "    stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "\n",
    "    # The next lines will handle the case where a single email is passed instead of an array of emails.\n",
    "    if isinstance(X, str):\n",
    "        X = np.array([X])\n",
    "\n",
    "    # The result will be stored in a list\n",
    "    X_preprocessed = []\n",
    "\n",
    "    for i, email in enumerate(X):\n",
    "        email = np.array([i.lower() for i in word_tokenize(email) if i.lower() not in stop]).astype(X.dtype)\n",
    "        X_preprocessed.append(email)\n",
    "        \n",
    "    if len(X) == 1:\n",
    "        return X_preprocessed[0]\n",
    "    return X_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0d80d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport nltk\\nnltk.download('stopwords')\\nnltk.download('punkt')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d102798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email before preprocessing: marketing for your espeak session  vince :  thanks for your time earlier this week ; i ' m looking forward to your espeak  event .  sarah and i met with our etv contact yesterday , and we will be able to put a  bulleted list on the elevator screens to advertise your espeak . please let  me know what you would like us to post for you , and we will do the rest !  we also have plans to market specifically to the trader community here at  enron , so you should get a high participation rate , especially from those  groups .  thanks , again .  - er\n",
      "Email after preprocessing: ['marketing' 'espeak' 'session' 'vince' 'thanks' 'time' 'earlier' 'week'\n",
      " 'looking' 'forward' 'espeak' 'event' 'sarah' 'met' 'etv' 'contact'\n",
      " 'yesterday' 'able' 'put' 'bulleted' 'list' 'elevator' 'screens'\n",
      " 'advertise' 'espeak' 'please' 'let' 'know' 'would' 'like' 'us' 'post'\n",
      " 'rest' 'also' 'plans' 'market' 'specifically' 'trader' 'community'\n",
      " 'enron' 'get' 'high' 'participation' 'rate' 'especially' 'groups'\n",
      " 'thanks' 'er']\n"
     ]
    }
   ],
   "source": [
    "X_treated = preprocess_text(X)\n",
    "email_index = 989\n",
    "print(f\"Email before preprocessing: {X[email_index]}\")\n",
    "print(f\"Email after preprocessing: {X_treated[email_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c44d6e",
   "metadata": {},
   "source": [
    "### Splitting into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871b453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = int(0.80*len(X_treated)) # 80% of the samples will be used to train.\n",
    "\n",
    "X_train = X_treated[:TRAIN_SIZE]\n",
    "Y_train = Y[:TRAIN_SIZE]\n",
    "X_test = X_treated[TRAIN_SIZE:]\n",
    "Y_test = Y[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c68d83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of spam in train dataset: 0.2431\n",
      "Proportion of spam in test dataset: 0.2216\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion of spam in train dataset: {sum(Y_train == 1)/len(Y_train):.4f}\")\n",
    "print(f\"Proportion of spam in test dataset: {sum(Y_test == 1)/len(Y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eecd370",
   "metadata": {},
   "source": [
    "### Implementing the Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e5d18",
   "metadata": {},
   "source": [
    "#### Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f413213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency(X,Y):\n",
    "    \"\"\"\n",
    "    Calculate the frequency of each word in a set of emails categorized as spam (1) or not spam (0).\n",
    "\n",
    "    Parameters:\n",
    "    - X (numpy.array): Array of emails, where each email is represented as a list of words.\n",
    "    - Y (numpy.array): Array of labels corresponding to each email in X. 1 indicates spam, 0 indicates ham.\n",
    "\n",
    "    Returns:\n",
    "    - word_dict (dict): A dictionary where keys are unique words found in the emails, and values\n",
    "      are dictionaries containing the frequency of each word for spam (1) and not spam (0) emails.\n",
    "    \"\"\"\n",
    "    # Creates an empty dictionary\n",
    "    word_dict = {}\n",
    "    num_emails = len(X)\n",
    "\n",
    "    # Iterates over every processed email and its label\n",
    "    for i in range(num_emails):\n",
    "        # Get the i-th email\n",
    "        email = X[i] \n",
    "        # Get the i-th label. This indicates whether the email is spam or not. 1 = None\n",
    "        # The variable name cls is an abbreviation for class, a reserved word in Python.\n",
    "        cls = Y[i] \n",
    "        # To avoid counting the same word twice in an email, remove duplicates by casting the email as a set\n",
    "        email = set(email) \n",
    "        # Iterates over every distinct word in the email\n",
    "        for word in email:\n",
    "            # If the word is not already in the dictionary, manually add it. Remember that you will start every word count as 1 both in spam and ham\n",
    "            if word not in word_dict.keys():\n",
    "                word_dict[word] = {'spam': 1, 'ham': 1}\n",
    "            # Add one occurrence for that specific word in the key ham if cls == 0 and spam if cls == 1. \n",
    "            if cls == 0:    \n",
    "                word_dict[word]['ham'] += 1\n",
    "            if cls == 1:\n",
    "                word_dict[word]['spam'] += 1\n",
    "\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e288dfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'like': {'spam': 2, 'ham': 1}, 'river': {'spam': 2, 'ham': 3}, 'going': {'spam': 2, 'ham': 1}, 'deep': {'spam': 1, 'ham': 2}, 'love': {'spam': 1, 'ham': 2}, 'hate': {'spam': 1, 'ham': 2}}\n"
     ]
    }
   ],
   "source": [
    "test_output = get_word_frequency([['like','going','river'], ['love', 'deep', 'river'], ['hate','river']], [1,0,0])\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ff4c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ham': 3468, 'spam': 1114}\n",
      "The proportion of spam emails in training is: 0.2431\n"
     ]
    }
   ],
   "source": [
    "word_frequency = get_word_frequency(X_train,Y_train)\n",
    "class_frequency = {'ham': sum(Y_train == 0), 'spam': sum(Y_train == 1)}\n",
    "print(class_frequency)\n",
    "proportion_spam = class_frequency['spam']/(class_frequency['ham'] + class_frequency['spam'])\n",
    "print(f\"The proportion of spam emails in training is: {proportion_spam:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c220d77",
   "metadata": {},
   "source": [
    "#### Find Word Probability $P(\\text{word} \\mid \\text{spam})$ and $P(\\text{word} \\mid \\text{ham})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec739846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_word_given_class(word, cls, word_frequency, class_frequency):\n",
    "    \"\"\"\n",
    "    Calculate the conditional probability of a given word occurring in a specific class.\n",
    "\n",
    "    Parameters:\n",
    "    - word (str): The target word for which the probability is calculated.\n",
    "    - cls (str): The class for which the probability is calculated, it may be 'spam' or 'ham'\n",
    "    - word_frequency (dict): The dictionary containing the words frequency.\n",
    "    - class_frequency (dict): The dictionary containing the class frequency.\n",
    "\n",
    "    Returns:\n",
    "    - float: The conditional probability of the given word occurring in the specified class.\n",
    "    \"\"\"  \n",
    "    # Get the amount of times the word appears with the given class (class is stores in spam variable)\n",
    "    amount_word_and_class = word_frequency[word][cls]\n",
    "    p_word_given_class = amount_word_and_class/class_frequency[cls]\n",
    "    \n",
    "    return p_word_given_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edba0ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(lottery | spam) = 0.00807899461400359\n",
      "P(lottery | ham) = 0.0002883506343713956\n",
      "P(schedule | spam) = 0.008976660682226212\n",
      "P(schedule | ham) = 0.10294117647058823\n"
     ]
    }
   ],
   "source": [
    "print(f\"P(lottery | spam) = {prob_word_given_class('lottery', cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
    "print(f\"P(lottery | ham) = {prob_word_given_class('lottery', cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
    "print(f\"P(schedule | spam) = {prob_word_given_class('schedule', cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
    "print(f\"P(schedule | ham) = {prob_word_given_class('schedule', cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e7ea1",
   "metadata": {},
   "source": [
    "#### Find Email Probability $P(\\text{email} \\mid \\text{spam})$ and $P(\\text{email} \\mid \\text{ham})$\n",
    "#### $$P(\\text{email} \\mid \\text{class}) = P(\\text{word}_1 \\mid \\text{class}) \\cdot P(\\text{word}_2 \\mid \\text{class}) \\cdots P(\\text{word}_n \\mid \\text{class})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "974ea2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_email_given_class(treated_email, cls, word_frequency, class_frequency):\n",
    "    \"\"\"\n",
    "    Calculate the probability of an email being of a certain class (e.g., spam or ham) based on treated email content.\n",
    "\n",
    "    Parameters:\n",
    "    - treated_email (list): A list of treated words in the email.\n",
    "    - cls (str): The class label for the email. It can be either 'spam' or 'ham'\n",
    "    - word_frequency (dict): The dictionary containing the words frequency.\n",
    "    - class_frequency (dict): The dictionary containing the class frequency.\n",
    "\n",
    "    Returns:\n",
    "    - float: The probability of the given email belonging to the specified class.\n",
    "    \"\"\"\n",
    "\n",
    "    # prob starts at 1 because it will be updated by multiplying it with the current P(word | class) in every iteration\n",
    "    prob = 1\n",
    "\n",
    "    for word in treated_email:\n",
    "        # Only perform the computation for words that exist in the word frequency dictionary\n",
    "        if word in word_frequency.keys(): \n",
    "            # Update the prob by multiplying it with P(word | class). \n",
    "            # Don't forget to add the word_frequency and class_frequency parameters!\n",
    "            prob *= prob_word_given_class(word, cls, word_frequency, class_frequency)\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c17e2c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: Click here to win a lottery ticket and claim your prize!\n",
      "Email after preprocessing: ['click' 'win' 'lottery' 'ticket' 'claim' 'prize']\n",
      "P(email | spam) = 5.3884806600117164e-11\n",
      "P(email | ham) = 1.2428344868918976e-15\n"
     ]
    }
   ],
   "source": [
    "example_email = \"Click here to win a lottery ticket and claim your prize!\"\n",
    "treated_email = preprocess_text(example_email)\n",
    "prob_spam = prob_email_given_class(treated_email, cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)\n",
    "prob_ham = prob_email_given_class(treated_email, cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)\n",
    "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nP(email | spam) = {prob_spam}\\nP(email | ham) = {prob_ham}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f3c9b6",
   "metadata": {},
   "source": [
    "#### Bayes Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66c45b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(treated_email, word_frequency, class_frequency, return_likelihood = False):    \n",
    "    \"\"\"\n",
    "    Naive Bayes classifier for spam detection.\n",
    "\n",
    "    This function calculates the probability of an email being spam (1) or ham (0)\n",
    "    based on the Naive Bayes algorithm. It uses the conditional probabilities of the\n",
    "    treated_email given spam and ham, as well as the prior probabilities of spam and ham\n",
    "    classes. The final decision is made by comparing the calculated probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    - treated_email (list): A preprocessed representation of the input email.\n",
    "    - word_frequency (dict): The dictionary containing the words frequency.\n",
    "    - class_frequency (dict): The dictionary containing the class frequency.\n",
    "    - return_likelihood (bool): If true, it returns the likelihood of both spam and ham.\n",
    "\n",
    "    Returns:\n",
    "    If return_likelihood = False:\n",
    "        - int: 1 if the email is classified as spam, 0 if classified as ham.\n",
    "    If return_likelihood = True:\n",
    "        - tuple: A tuple with the format (spam_likelihood, ham_likelihood)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute P(email | spam) with the function you defined just above. \n",
    "    # Don't forget to add the word_frequency and class_frequency parameters!\n",
    "    prob_email_given_spam = prob_email_given_class(treated_email, 'spam', word_frequency, class_frequency)\n",
    "\n",
    "    # Compute P(email | ham) with the function you defined just above. \n",
    "    # Don't forget to add the word_frequency and class_frequency parameters!\n",
    "    prob_email_given_ham = prob_email_given_class(treated_email, 'ham', word_frequency, class_frequency)\n",
    "\n",
    "    # Compute P(spam) using the class_frequency dictionary and using the formula #spam emails / #total emails\n",
    "    p_spam = class_frequency['spam'] / sum(class_frequency.values())\n",
    "\n",
    "    # Compute P(ham) using the class_frequency dictionary and using the formula #ham emails / #total emails\n",
    "    p_ham = class_frequency['ham'] / sum(class_frequency.values())\n",
    "\n",
    "    # Compute the quantity P(spam) * P(email | spam), let's call it spam_likelihood\n",
    "    spam_likelihood = p_spam * prob_email_given_spam\n",
    "\n",
    "    # Compute the quantity P(ham) * P(email | ham), let's call it ham_likelihood\n",
    "    ham_likelihood = p_ham * prob_email_given_ham\n",
    "\n",
    "    # In case of passing return_likelihood = True, then return the desired tuple\n",
    "    if return_likelihood == True:\n",
    "        return (spam_likelihood, ham_likelihood)\n",
    "    \n",
    "    # Compares both values and choose the class corresponding to the higher value\n",
    "    elif spam_likelihood >= ham_likelihood:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a659fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: Click here to win a lottery ticket and claim your prize!\n",
      "Email after preprocessing: ['click' 'win' 'lottery' 'ticket' 'claim' 'prize']\n",
      "Naive Bayes predicts this email as: 1\n",
      "\n",
      "\n",
      "\n",
      "Email: Our meeting will happen in the main office. Please be there in time.\n",
      "Email after preprocessing: ['meeting' 'happen' 'main' 'office' 'please' 'time']\n",
      "Naive Bayes predicts this email as: 0\n"
     ]
    }
   ],
   "source": [
    "example_email = \"Click here to win a lottery ticket and claim your prize!\"\n",
    "treated_email = preprocess_text(example_email)\n",
    "\n",
    "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nNaive Bayes predicts this email as: {naive_bayes(treated_email, word_frequency, class_frequency)}\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "example_email = \"Our meeting will happen in the main office. Please be there in time.\"\n",
    "treated_email = preprocess_text(example_email)\n",
    "\n",
    "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nNaive Bayes predicts this email as: {naive_bayes(treated_email, word_frequency, class_frequency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d072c59",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a84d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_positives(Y_true, Y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the number of true positive instances in binary classification.\n",
    "\n",
    "    Parameters:\n",
    "    - Y_true (list): List of true labels (0 or 1) for each instance.\n",
    "    - Y_pred (list): List of predicted labels (0 or 1) for each instance.\n",
    "\n",
    "    Returns:\n",
    "    - int: Number of true positives, where true label and predicted label are both 1.\n",
    "    \"\"\"\n",
    "    # Both Y_true and Y_pred must match in length.\n",
    "    if len(Y_true) != len(Y_pred):\n",
    "        return \"Number of true labels and predict labels must match!\"\n",
    "    n = len(Y_true)\n",
    "    true_positives = 0\n",
    "    # Iterate over the number of elements in the list\n",
    "    for i in range(n):\n",
    "        # Get the true label for the considered email\n",
    "        true_label_i = Y_true[i]\n",
    "        # Get the predicted (model output) for the considered email\n",
    "        predicted_label_i = Y_pred[i]\n",
    "        # Increase the counter by 1 only if true_label_i = 1 and predicted_label_i = 1 (true positives)\n",
    "        if true_label_i == 1 and predicted_label_i == 1:\n",
    "            true_positives += 1\n",
    "    return true_positives\n",
    "        \n",
    "def get_true_negatives(Y_true, Y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the number of true negative instances in binary classification.\n",
    "\n",
    "    Parameters:\n",
    "    - Y_true (list): List of true labels (0 or 1) for each instance.\n",
    "    - Y_pred (list): List of predicted labels (0 or 1) for each instance.\n",
    "\n",
    "    Returns:\n",
    "    - int: Number of true negatives, where true label and predicted label are both 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Both Y_true and Y_pred must match in length.\n",
    "    if len(Y_true) != len(Y_pred):\n",
    "        return \"Number of true labels and predict labels must match!\"\n",
    "    n = len(Y_true)\n",
    "    true_negatives = 0\n",
    "    # Iterate over the number of elements in the list\n",
    "    for i in range(n):\n",
    "        # Get the true label for the considered email\n",
    "        true_label_i = Y_true[i]\n",
    "        # Get the predicted (model output) for the considered email\n",
    "        predicted_label_i = Y_pred[i]\n",
    "        # Increase the counter by 1 only if true_label_i = 0 and predicted_label_i = 0 (true negatives)\n",
    "        if true_label_i == 0 and predicted_label_i == 0:\n",
    "            true_negatives += 1\n",
    "    return true_negatives\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c99e457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test and Y_pred matches in length? Answer: True\n"
     ]
    }
   ],
   "source": [
    "# Let's get the predictions for the test set:\n",
    "\n",
    "# Create an empty list to store the predictions\n",
    "Y_pred = []\n",
    "\n",
    "\n",
    "# Iterate over every email in the test set\n",
    "for email in X_test:\n",
    "    # Perform prediction\n",
    "    prediction = naive_bayes(email, word_frequency, class_frequency)\n",
    "    # Add it to the list \n",
    "    Y_pred.append(prediction)\n",
    "\n",
    "# Checking if both Y_pred and Y_test (these are the true labels) match in length:\n",
    "print(f\"Y_test and Y_pred matches in length? Answer: {len(Y_pred) == len(Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e372423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true positives is: 249\n",
      "The number of true negatives is: 723\n",
      "Accuracy is: 0.8482\n"
     ]
    }
   ],
   "source": [
    "# Get the number of true positives:\n",
    "true_positives = get_true_positives(Y_test, Y_pred)\n",
    "\n",
    "# Get the number of true negatives:\n",
    "true_negatives = get_true_negatives(Y_test, Y_pred)\n",
    "\n",
    "print(f\"The number of true positives is: {true_positives}\\nThe number of true negatives is: {true_negatives}\")\n",
    "\n",
    "# Compute the accuracy by summing true negatives with true positives and dividing it by the total number of elements in the dataset. \n",
    "# Since both Y_pred and Y_test have the same length, it does not matter which one you use.\n",
    "accuracy = (true_positives + true_negatives)/len(Y_test)\n",
    "\n",
    "print(f\"Accuracy is: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6995e8",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83d63ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email is: You win a lottery prize! Congratulations! Click here to claim it\n",
      "The model predicts it as spam.\n"
     ]
    }
   ],
   "source": [
    "#email = \"Please meet me in 2 hours in the main building. I have an important task for you.\"\n",
    "email = \"You win a lottery prize! Congratulations! Click here to claim it\"\n",
    "\n",
    "# Preprocess the email\n",
    "treated_email = preprocess_text(email)\n",
    "# Get the prediction, in order to print it nicely, if the output is 1 then the prediction will be written as \"spam\" otherwise \"ham\".\n",
    "prediction = \"spam\" if naive_bayes(treated_email, word_frequency, class_frequency) == 1 else \"ham\"\n",
    "print(f\"The email is: {email}\\nThe model predicts it as {prediction}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261087b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
